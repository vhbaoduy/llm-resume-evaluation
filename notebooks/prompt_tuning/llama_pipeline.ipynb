{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dceb0402",
   "metadata": {},
   "source": [
    "# State and Output Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f97e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic model to structure the LLM's output\n",
    "class ScorePrediction(BaseModel):\n",
    "    \"\"\"The structured output for the resume score.\"\"\"\n",
    "\n",
    "    score: float = Field(description=\"The matching score between JD and Resume (0–10)\")\n",
    "    explanation: str = Field(description=\"The explanation of the matching score\")\n",
    "\n",
    "\n",
    "# The state that will be passed through the graph\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"The state of our graph.\"\"\"\n",
    "\n",
    "    jd: str\n",
    "    resume: str\n",
    "    prediction: ScorePrediction  # The final output will be stored here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f857d58",
   "metadata": {},
   "source": [
    "# Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aef7698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# The complete, optimized prompt generated by DSPy\n",
    "OPTIMIZED_PROMPT_TEMPLATE = \"\"\"\n",
    "# SYSTEM INSTRUCTION\n",
    "Your input fields are:\n",
    "1. `jd` (str): The job description text\n",
    "2. `resume` (str): The candidate's resume text\n",
    "Your output fields are:\n",
    "1. `score` (str): The matching score between JD and Resume (0–10)\n",
    "2. `explanation` (str): The explanation of the matching score\n",
    "All interactions will be structured in the following way, with the appropriate values filled in.\n",
    "\n",
    "[[ ## jd ## ]]\n",
    "{{jd}}\n",
    "\n",
    "[[ ## resume ## ]]\n",
    "{{resume}}\n",
    "\n",
    "[[ ## score ## ]]\n",
    "{{score}}\n",
    "\n",
    "[[ ## explanation ## ]]\n",
    "{{explanation}}\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "In adhering to this structure, your objective is: \n",
    "        Given a job description and a resume, predict a matching score (0-10).\n",
    "\n",
    "# FEW-SHOT EXAMPLE 1\n",
    "[[ ## jd ## ]]\n",
    "Software Engineer needed with experience in Git, Docker, Java, REST APIs. Hit summer discussion culture measure ever.\n",
    "\n",
    "[[ ## resume ## ]]\n",
    "Experienced professional skilled in System Design, past, Java, foot. Thank case rather generation inside. Raise new structure race.\n",
    "\n",
    "[[ ## score ## ]]\n",
    "4\n",
    "\n",
    "[[ ## explanation ## ]]\n",
    "Not supplied for this particular example.\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "\n",
    "# FEW-SHOT EXAMPLE 2\n",
    "[[ ## jd ## ]]\n",
    "ML Engineer needed with experience in Python, PyTorch, Computer Vision, TensorFlow, Keras. Could chair beautiful social both few through. Entire card much rate politics their identify. Pass sing goal during be those.\n",
    "\n",
    "[[ ## resume ## ]]\n",
    "Experienced professional skilled in Computer Vision, Python, MLOps, PyTorch, TensorFlow, parent. Exactly section network detail. Short out team author deal hospital able.\n",
    "\n",
    "[[ ## score ## ]]\n",
    "10\n",
    "\n",
    "[[ ## explanation ## ]]\n",
    "Not supplied for this particular example.\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "\n",
    "# FEW-SHOT EXAMPLE 3\n",
    "[[ ## jd ## ]]\n",
    "ML Engineer needed with experience in TensorFlow, Computer Vision, Keras, PyTorch, MLOps. Approach wish fine near. Agree long behind stuff how positive tree. Quality team general office painting official.\n",
    "\n",
    "[[ ## resume ## ]]\n",
    "Experienced professional skilled in Cloud, interest, MLOps, Keras, hotel, PyTorch. Address guy fund window well impact quite. Place raise really feeling vote per. Catch board present market society fight foreign. Out generation beyond six degree stop.\n",
    "\n",
    "[[ ## score ## ]]\n",
    "8\n",
    "\n",
    "[[ ## explanation ## ]]\n",
    "Not supplied for this particular example.\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "\n",
    "# FEW-SHOT EXAMPLE 4\n",
    "[[ ## jd ## ]]\n",
    "Data Scientist needed with experience in Deep Learning, Machine Learning, NLP, SQL, Pandas, Python, Statistics. Nearly computer close garden. Law individual business hair show. Final though kitchen purpose five. Use sea right civil.\n",
    "\n",
    "[[ ## resume ## ]]\n",
    "Experienced professional skilled in Python, Deep Learning, garden, Statistics, SQL, Pandas, stock. Note operation despite born. Step take share million message long board.\n",
    "\n",
    "[[ ## score ## ]]\n",
    "8\n",
    "\n",
    "[[ ## explanation ## ]]\n",
    "Not supplied for this particular example.\n",
    "\n",
    "[[ ## completed ## ]]\n",
    "\n",
    "# FINAL QUERY\n",
    "[[ ## jd ## ]]\n",
    "{jd}\n",
    "\n",
    "[[ ## resume ## ]]\n",
    "{resume}\n",
    "\n",
    "Respond with the corresponding output fields, starting with the field `[[ ## score ## ]]`, then `[[ ## explanation ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def scorer_node(state: GraphState):\n",
    "    \"\"\"Invokes the LLM to score the resume against the job description.\"\"\"\n",
    "\n",
    "    model = ChatOllama(\n",
    "        model=\"llama3.2:1b\",  # Or another model like 'llama3:70b', 'mistral', etc.\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    # Create the prompt from the template\n",
    "    prompt = ChatPromptTemplate.from_template(OPTIMIZED_PROMPT_TEMPLATE)\n",
    "\n",
    "    # Create the chain\n",
    "    chain = prompt | model\n",
    "\n",
    "    # Get inputs from the state\n",
    "    jd = state[\"jd\"]\n",
    "    resume = state[\"resume\"]\n",
    "\n",
    "    # Invoke the chain\n",
    "    response = chain.invoke({\"jd\": jd, \"resume\": resume})\n",
    "    response_text = response.content\n",
    "\n",
    "    # Parse the structured output from the model's response\n",
    "    try:\n",
    "        score_match = re.search(r\"\\[\\[ ## score ## \\]\\]\\s*([\\d.]+)\", response_text)\n",
    "        explanation_match = re.search(\n",
    "            r\"\\[\\[ ## explanation ## \\]\\]\\s*([\\s\\S]*?)\\s*\\[\\[ ## completed ## \\]\\]\",\n",
    "            response_text,\n",
    "        )\n",
    "\n",
    "        if not score_match or not explanation_match:\n",
    "            raise ValueError(\"Could not find score or explanation tags in the output.\")\n",
    "\n",
    "        score_val = float(score_match.group(1).strip())\n",
    "        explanation_val = explanation_match.group(1).strip()\n",
    "\n",
    "        prediction = ScorePrediction(score=score_val, explanation=explanation_val)\n",
    "\n",
    "    except (ValueError, AttributeError) as e:\n",
    "        print(f\"Error parsing LLM output: {e}\\nResponse: {response_text}\")\n",
    "        # Assign a default low score on parsing failure\n",
    "        prediction = ScorePrediction(\n",
    "            score=0.0, explanation=\"Failed to parse model output.\"\n",
    "        )\n",
    "\n",
    "    return {\"prediction\": prediction}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af82b5",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7cc68fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ LangGraph App Compiled Successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pk/36_zplxd57l142tqyrqqmmkh0000gp/T/ipykernel_91454/4204216905.py:107: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  model = ChatOllama(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Result ---\n",
      "Score: 4.0\n",
      "Explanation: Not supplied for this particular example.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Initialize the graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add the scorer node\n",
    "workflow.add_node(\"scorer\", scorer_node)\n",
    "\n",
    "# Set the entry point and the final edge\n",
    "workflow.set_entry_point(\"scorer\")\n",
    "workflow.add_edge(\"scorer\", END)\n",
    "\n",
    "# Compile the graph into a runnable application\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"\\n✅ LangGraph App Compiled Successfully!\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "jd_example = \"Product Manager needed with experience in User Stories, Product Roadmap, Stakeholder Management, Agile.\"\n",
    "resume_example = \"Experienced professional skilled in blood, Scrum, skill, Stakeholder Management, quality, Agile.\"\n",
    "\n",
    "inputs = {\"jd\": jd_example, \"resume\": resume_example}\n",
    "\n",
    "# Run the graph\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(\"\\n--- Example Result ---\")\n",
    "print(f\"Score: {result['prediction'].score}\")\n",
    "print(f\"Explanation: {result['prediction'].explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a43152",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74457447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "def accuracy_at_threshold(gold_scores, pred_scores, threshold):\n",
    "    gold_scores = np.array(gold_scores)\n",
    "    pred_scores = np.array(pred_scores)\n",
    "    absolute_errors = np.abs(gold_scores - pred_scores)\n",
    "    within_threshold_count = np.sum(absolute_errors <= threshold)\n",
    "    return within_threshold_count / len(gold_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a96d4c",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee69387",
   "metadata": {},
   "source": [
    "## Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d863337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"../../data/train.csv\")\n",
    "val_df = pd.read_csv(\"../../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d302e4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Evaluation on 3000 examples ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:   0%|          | 8/3000 [02:46<16:40:15, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: # SYSTEM INSTRUCTION\n",
      "Your input fields are:\n",
      "1. `jd` (str): The job description text\n",
      "2. `resume` (str): The candidate's resume text\n",
      "\n",
      "## JD\n",
      "Software Engineer needed with experience in Git, Java, System Design, REST APIs, Docker.\n",
      "\n",
      "## Resume\n",
      "Experienced professional skilled in System Design, cultural, race, Docker, Java, Spring Boot, Git. Again race agency late energy avoid. Instead get property instead gun decide laugh. Number beat none mention agree room.\n",
      "\n",
      "## Score\n",
      "8\n",
      "\n",
      "## Explanation\n",
      "The matching score between JD and Resume is 8. This suggests that the candidate's resume contains relevant information about their experience in software engineering, system design, and Docker, but does not explicitly state this. The explanation for the match is \"Not supplied\".\n",
      "\n",
      "## Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:   1%|          | 31/3000 [2:34:14<116:50:13, 141.67s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: # SYSTEM INSTRUCTION\n",
      "Your input fields are:\n",
      "1. `jd` (str): The job description text\n",
      "2. `resume` (str): The candidate's resume text\n",
      "\n",
      "## JD\n",
      "Software Engineer needed with experience in REST APIs, Docker, Java, Spring Boot, Git.\n",
      "\n",
      "## Resume\n",
      "Experienced professional skilled in Git, Docker, much, Spring Boot, Agile. Good continue tonight apply.\n",
      "\n",
      "## Score\n",
      "8\n",
      "\n",
      "## Explanation\n",
      "The matching score between the job description and the resume is 8 because both mention relevant skills such as REST APIs, Docker, Java, and Spring Boot.\n",
      "\n",
      "## Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:   3%|▎         | 93/3000 [5:17:15<54:01:29, 66.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: # SYSTEM INSTRUCTION\n",
      "Your input fields are:\n",
      "1. `jd` (str): The job description text\n",
      "2. `resume` (str): The candidate's resume text\n",
      "\n",
      "## JD\n",
      "Software Engineer needed with experience in System Design, REST APIs, Agile, Spring Boot, Docker, Java.\n",
      "\n",
      "## Resume\n",
      "Experienced professional skilled in System Design, Java, Git, Spring Boot, REST APIs. Though black present find break final allow. Time since field than likely religious human.\n",
      "\n",
      "## Score\n",
      "8\n",
      "\n",
      "## Explanation\n",
      "The matching score between JD and Resume is 8 because the job description mentions \"System Design\", \"REST APIs\", \"Agile\", \"Spring Boot\", and \"Docker\" which are all relevant skills for a Software Engineer position, but it does not mention Java. However, the resume mentions \"Java\" as one of its relevant skills.\n",
      "\n",
      "## Completed\n",
      "[[ ## completed ## ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:   8%|▊         | 237/3000 [9:46:19<114:13:12, 148.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: # SYSTEM INSTRUCTION\n",
      "Your input fields are:\n",
      "1. `jd` (str): The job description text\n",
      "2. `resume` (str): The candidate's resume text\n",
      "\n",
      "## JD\n",
      "Software Engineer needed with experience in Java, Docker, System Design, Spring Boot, Agile, REST APIs, Git.\n",
      "\n",
      "## Resume\n",
      "Experienced professional skilled in body, Java, System Design, Docker, Agile. Memory single modern itself other. Cover hospital end. Five wish stuff only. Institution information bill collection tend this.\n",
      "\n",
      "## Score\n",
      "8\n",
      "\n",
      "## Explanation\n",
      "The matching score between JD and Resume is 8 because the candidate's resume mentions experience with Spring Boot, which is not mentioned in the job description. The explanation for the mismatch is that the job description does not mention Docker or Agile, but the resume mentions these technologies.\n",
      "\n",
      "## Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  15%|█▌        | 455/3000 [18:24:00<80:46:33, 114.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: # SYSTEM INSTRUCTION\n",
      "Your input fields are:\n",
      "1. `jd` (str): The job description text\n",
      "2. `resume` (str): The candidate's resume text\n",
      "\n",
      "## JD\n",
      "Software Engineer needed with experience in System Design, Docker, Spring Boot, Git, Java, REST APIs, Agile.\n",
      "\n",
      "## Resume\n",
      "Experienced professional skilled in Java, interview, Docker. Model although national anything fine low make. Give voice only visit.\n",
      "\n",
      "## Score\n",
      "8\n",
      "\n",
      "## Explanation\n",
      "The matching score between the job description and resume is 8 out of 10. The candidate's experience in System Design, Spring Boot, Git, and Java aligns well with the job requirements, while their experience in Docker and Agile also shows a good fit. However, there are no specific skills mentioned that match the job description perfectly.\n",
      "\n",
      "## Completed\n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  23%|██▎       | 703/3000 [31:14:52<102:06:01, 160.02s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m inputs = {\u001b[33m\"\u001b[39m\u001b[33mjd\u001b[39m\u001b[33m\"\u001b[39m: jd, \u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m: resume}\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     result = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     pred_score = result[\u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m].score\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langgraph/pregel/main.py:3085\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3082\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3083\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3085\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3087\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3088\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3090\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3091\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3093\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3094\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3095\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3097\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3098\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3099\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3100\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langgraph/pregel/main.py:2674\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2672\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2673\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2675\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2677\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2679\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2680\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2681\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2683\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2684\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langgraph/pregel/_runner.py:162\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    160\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langgraph/pregel/_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:657\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m657\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langgraph/_internal/_runnable.py:401\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    399\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 123\u001b[39m, in \u001b[36mscorer_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    120\u001b[39m resume = state[\u001b[33m\"\u001b[39m\u001b[33mresume\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# Invoke the chain\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m response = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjd\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mjd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresume\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresume\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m response_text = response.content\n\u001b[32m    126\u001b[39m \u001b[38;5;66;03m# Parse the structured output from the model's response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langchain_core/runnables/base.py:3246\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3244\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3245\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3246\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3247\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3248\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1025\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1016\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     **kwargs: Any,\n\u001b[32m   1023\u001b[39m ) -> LLMResult:\n\u001b[32m   1024\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1025\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:842\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    840\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    841\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m842\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m         )\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    850\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1091\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1089\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1090\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1095\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langchain_community/chat_models/ollama.py:291\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    269\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    272\u001b[39m     **kwargs: Any,\n\u001b[32m    273\u001b[39m ) -> ChatResult:\n\u001b[32m    274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[32m    275\u001b[39m \n\u001b[32m    276\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    288\u001b[39m \u001b[33;03m            ])\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    299\u001b[39m         message=AIMessage(content=final_chunk.text),\n\u001b[32m    300\u001b[39m         generation_info=final_chunk.generation_info,\n\u001b[32m    301\u001b[39m     )\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations=[chat_generation])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langchain_community/chat_models/ollama.py:222\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    214\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    215\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     **kwargs: Any,\n\u001b[32m    220\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    221\u001b[39m     final_chunk: Optional[ChatGenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/langchain_community/chat_models/ollama.py:194\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_chat_stream\u001b[39m(\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    186\u001b[39m     messages: List[BaseMessage],\n\u001b[32m    187\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    188\u001b[39m     **kwargs: Any,\n\u001b[32m    189\u001b[39m ) -> Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    190\u001b[39m     payload = {\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._convert_messages_to_ollama_messages(messages),\n\u001b[32m    193\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_stream(\n\u001b[32m    195\u001b[39m         payload=payload, stop=stop, api_url=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/chat\u001b[39m\u001b[33m\"\u001b[39m, **kwargs\n\u001b[32m    196\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/requests/models.py:869\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self, chunk_size, decode_unicode, delimiter)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[32m    861\u001b[39m \u001b[33;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[32m    862\u001b[39m \u001b[33;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[32m    863\u001b[39m \n\u001b[32m    864\u001b[39m \u001b[33;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[32m    865\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    867\u001b[39m pending = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/requests/utils.py:562\u001b[39m, in \u001b[36mstream_decode_response_unicode\u001b[39m\u001b[34m(iterator, r)\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    561\u001b[39m decoder = codecs.getincrementaldecoder(r.encoding)(errors=\u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/urllib3/response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/urllib3/response.py:1248\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1245\u001b[39m     amt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/HCMUS/LLM/Code/llm-resume-evaluation/.env/lib/python3.12/site-packages/urllib3/response.py:1167\u001b[39m, in \u001b[36mHTTPResponse._update_chunk_length\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1168\u001b[39m line = line.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "gold_scores = []\n",
    "pred_scores = []\n",
    "\n",
    "print(f\"\\n--- Starting Evaluation on {len(val_df)} examples ---\")\n",
    "\n",
    "for i, example in tqdm(\n",
    "    val_df.iterrows(), desc=\"Evaluating LangGraph\", total=len(val_df)\n",
    "):\n",
    "    # Get ground truth data\n",
    "    jd = example[\"job_description\"]\n",
    "    resume = example[\"resume\"]\n",
    "    gold_score = example[\"match_score\"]\n",
    "\n",
    "    # Run the LangGraph app\n",
    "    inputs = {\"jd\": jd, \"resume\": resume}\n",
    "    try:\n",
    "        result = app.invoke(inputs)\n",
    "        pred_score = result[\"prediction\"].score\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during graph execution: {e}\")\n",
    "        pred_score = 0.0  # Assign a penalty score\n",
    "\n",
    "    gold_scores.append(gold_score)\n",
    "    pred_scores.append(pred_score)\n",
    "\n",
    "    # To avoid rate limiting\n",
    "    time.sleep(1)\n",
    "\n",
    "print(\"--- Evaluation Complete ---\")\n",
    "\n",
    "# --- Calculate Metrics ---\n",
    "\n",
    "# 1. Mean Absolute Error (MAE)\n",
    "final_mae = mean_absolute_error(gold_scores, pred_scores)\n",
    "\n",
    "# 2. Accuracy@threshold\n",
    "acc_at_1 = accuracy_at_threshold(gold_scores, pred_scores, threshold=1)\n",
    "acc_at_2 = accuracy_at_threshold(gold_scores, pred_scores, threshold=2)\n",
    "acc_at_3 = accuracy_at_threshold(gold_scores, pred_scores, threshold=3)\n",
    "\n",
    "\n",
    "# --- Print Results ---\n",
    "\n",
    "print(\"\\n--- LangGraph Evaluation Results ---\")\n",
    "print(f\"📊 Mean Absolute Error (MAE): {final_mae:.4f}\")\n",
    "print(\"---\")\n",
    "print(f\"🎯 Accuracy@1 (error <= 1.0): {acc_at_1:.2%}\")\n",
    "print(f\"🎯 Accuracy@2 (error <= 2.0): {acc_at_2:.2%}\")\n",
    "print(f\"🎯 Accuracy@3 (error <= 3.0): {acc_at_3:.2%}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf9678",
   "metadata": {},
   "source": [
    "## Collected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9705152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  11%|█▏        | 10/87 [02:12<13:44, 10.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8. This score indicates that the job description provided in the job posting matches the skills and experience required by the candidate's resume.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "Note: The output fields are filled with the corresponding values based on the analysis of the input fields \"jd\" and \"resume\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  14%|█▍        | 12/87 [02:26<11:23,  9.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8. This indicates that there are some similarities in the job description and resume, but not enough to guarantee a perfect match.\n",
      "\n",
      "The key areas where the two documents show similarities include:\n",
      "\n",
      "* The use of technical terms related to data science and machine learning\n",
      "* The mention of specific tools and technologies such as Hadoop, Spark, and PySpark\n",
      "* The emphasis on data preprocessing, feature engineering, and model training\n",
      "\n",
      "However, there are also some differences that prevent a perfect match. For example:\n",
      "\n",
      "* The job description mentions the need for \"quick access to legal information\" which is not explicitly mentioned in the resume\n",
      "* The resume does not mention any experience with Power BI or Hugging Face models\n",
      "* There is no mention of specific data visualization tools such as Tableau or D3.js\n",
      "\n",
      "Overall, while there are some similarities between the job description and resume, there are also enough differences to prevent a perfect match.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  15%|█▍        | 13/87 [02:40<12:42, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{10}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 10 because the candidate's resume mentions experience in data science, AI engineering, and machine learning, which are relevant to the job description. The candidate also has a strong background in Python, Big Data, Power BI, and libraries such as pandas, matplotlib, and scikit-learn.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "Note: Since there is no information provided about the candidate's experience or skills that match the job requirements, the score of 10 is based on the general relevance of the candidate's resume to the job description.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  16%|█▌        | 14/87 [02:48<11:56,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the candidate's resume mentions experience in Data Science/AI Engineer, which matches the job description. The candidate also has relevant skills such as Python, Big Data, Power Bi, Libraies and frameworks like pandas, matplotlib, numpy, Apache Hadoop, PySpark, Tools like Power Query, Visualize, BeutifulSoup4, re, os, scikit-learn, SQL, C++, Hugging Face, transformers, PyTorch, Python-Flask, LangChain, NLTK. The candidate's experience in Machine Learning and Deep Learning is also relevant to the job description.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "Note: The score of 8 indicates a good match between the job description and the resume, but it does not guarantee that the candidate will get the job. Other factors such as the quality of the resume, the relevance of the skills mentioned in the resume to the job description, and the fit with the company culture may also play a role in the hiring decision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  17%|█▋        | 15/87 [03:01<12:53, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{10}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 10 because the candidate's resume mentions experience in deep learning, machine learning, NLP, SQL, Pandas, Statistics, which are all relevant to a Data Scientist role. The job description also mentions building real-world AI products that touch millions of users, which aligns with the responsibilities of a Data Scientist.\n",
      "\n",
      "[[ ## completed ## ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  18%|█▊        | 16/87 [03:09<11:33,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is based on the similarity in job description, skills, and experience. The candidate's resume highlights their expertise in Data Science/AI Engineer, while the job description emphasizes software development, data analysis, and problem-solving.\n",
      "\n",
      "The key similarities are:\n",
      "\n",
      "* Both candidates have a strong background in programming languages (Python, Java, etc.)\n",
      "* They both have experience with machine learning models (e.g., TensorFlow, PyTorch)\n",
      "* The candidate's resume mentions their experience with Big Data technologies (Apache Hadoop, Spark) and data visualization tools (Power BI)\n",
      "\n",
      "However, there are also some differences:\n",
      "\n",
      "* The job description requires a Full Stack Engineer, while the candidate's resume focuses on Data Science/AI Engineer\n",
      "* The candidate's resume highlights their expertise in computer vision and natural language processing, which is not mentioned in the job description\n",
      "\n",
      "Overall, the matching score is 8 out of 10, indicating that there are some similarities between the JD and Resume, but also some differences that may make it challenging to find a perfect match.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  22%|██▏       | 19/87 [03:45<12:24, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "# AI Engineer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  24%|██▍       | 21/87 [04:01<10:33,  9.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the candidate's resume mentions their experience in Data Science, Machine Learning, NLP, SQL, Pandas, Statistics, and Python, while the job description requires expertise in Big Data Engineering, Data Science, Machine Learning, and Python. The candidate also mentions their desire to work on projects related to IoT Cloud platform, credit card default predict, and cybersecurity.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "No completion information is provided for this example.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  25%|██▌       | 22/87 [04:10<09:58,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8.\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "This match is due to the presence of similar keywords in both job description and candidate's resume, such as \"Data Engineer\", \"Machine Learning\", \"Python\", \"Big Data\", etc. The candidate's experience in handling large data sets (multiple TBs), designing solutions that provide analytics in real-time, growing our Data Platform, ensuring the data quality and consistency with monitoring and support, creating more tools and frameworks for processing big data, and designing and building dashboard, report to visualize data are all relevant skills and experiences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  26%|██▋       | 23/87 [04:18<09:25,  8.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because Duy Anh Tran's resume highlights his experience in Data Science, Machine Learning, and Python programming skills, while the job description mentions specific requirements such as \"Software Engineer needed with experience in Git, Docker, Java, REST APIs\" and \"Data Scientist needed with experience in Deep Learning, Machine Learning, NLP, SQL, Pandas, Statistics\". The most relevant skills mentioned in both are Data Science, Machine Learning, Python programming, and statistics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  28%|██▊       | 24/87 [04:24<08:39,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is based on the similarity in job description, skills, and experience. The candidate's resume highlights their strong technical foundation, industry experience, and problem-solving mindset, which aligns well with the requirements of the job.\n",
      "\n",
      "The key similarities are:\n",
      "\n",
      "* Both candidates have a strong background in computer science and software engineering.\n",
      "* They both have experience working on machine learning projects, including object detection and credit card default prediction.\n",
      "* Both candidates have a good understanding of data science libraries such as TensorFlow, PyTorch, and Scikit-Learn.\n",
      "* They both have experience with SQL and cloud platforms.\n",
      "\n",
      "However, there are also some differences:\n",
      "\n",
      "* The candidate's resume mentions their experience working on a remote team, which is not mentioned in the job description.\n",
      "* The candidate's resume highlights their ability to learn new technologies quickly, whereas the job description does not mention this as a key requirement.\n",
      "\n",
      "Overall, the matching score between JD and Resume is 8 out of 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  31%|███       | 27/87 [04:50<08:35,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8.\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "This match is based on the following similarities:\n",
      "\n",
      "* Both job descriptions mention experience in machine learning, deep learning, and natural language processing.\n",
      "* The resumes highlight skills such as Python, TensorFlow, PyTorch, and Keras, which are also mentioned in the job description.\n",
      "* The resumes also mention experience with recommendation systems, ad targeting models, and real-time bidding, which are not explicitly mentioned in the job description but can be inferred from the context.\n",
      "\n",
      "The only difference is that the resume mentions a specific project (vision-based state recognition of 220Kv and 110kv disconnectors switches) that is not mentioned in the job description. However, this project does not seem to be directly related to the skills or experience listed in the job description, so it can be considered as an outlier.\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The explanation for this match is based on the similarities between the job descriptions and resumes, as well as the differences that are not explicitly mentioned in either document.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  32%|███▏      | 28/87 [04:59<08:33,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the job description mentions experience in developing and deploying practical AI models, which aligns with the candidate's background as an experienced professional skilled in Computer Vision, Python, MLOps, PyTorch, TensorFlow, and Cloud. The candidate also mentions working on AI research projects and publications, which further supports this match.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "No\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  36%|███▌      | 31/87 [05:20<07:03,  7.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: # SYSTEM INSTRUCTION\n",
      "Your input fields are:\n",
      "1. `jd` (str): The job description text\n",
      "2. `resume` (str): The candidate's resume text\n",
      "\n",
      "## FEW-SHOT EXAMPLE 1\n",
      "[[ ## jd ## ]]\n",
      "We are looking for a Data Engineer to join our journey developing the next gen retails system of 7-Eleven Viet Nam.\n",
      "\n",
      "RESPONSIBILITY\n",
      "\n",
      "Develop difference technology projects of 7-Eleven VN\n",
      "Work closely with product managers and business stakeholders, analyze the requirements and feedback to improve the requirement itself\n",
      "Participate in all stages of agile product development life cycle with Scrum\n",
      "REQUIREMENT\n",
      "\n",
      "1-5 years of experience in handling large data sets (multiple TBs), or development of data mart, data warehouse, data extraction and transformation between systems. \n",
      "Have experience in at least one of the following: PostgreSQL, MongoDB or BigQuery.\n",
      "Build scalable and reliable ETL pipelines and processes to assemble data from a large number and variety of data sources.\n",
      "Designing solutions that provide analytics in real-time.\n",
      "Growing our Data Platform so that new data requirements can be done quickly.\n",
      "Ensure the data quality and consistency with monitoring and support, and play an active role in establishing data governance from different sources.\n",
      "Creating more tools and frameworks for processing big data.\n",
      "Design and build dashboard, report to visualize data.\n",
      "Support the development team to design the features that use analytics data.\n",
      "You will love working with 7-Lab  because\n",
      "\n",
      "“We are cool”\n",
      "\n",
      "Optimizing for scale, handling millions records of data\n",
      "Building real-time retails system at scale with Kafka\n",
      "Developing Retail Management System that includes Ecommerce Website, Loyalty Application, Master Data System, Supply Chain System, Warehouse Management System and POS. Refer on https://www.7-eleven.vn/\n",
      "Morden tech stack (Google Cloud Platform, Docker, Kubernetes, Rancher) and tools (Google Chat, Jira) \n",
      "Catching up with new technologies through the process: experiment, trial, adopt \n",
      "In partnership with Grab, Moca, Google for tech & digital integrations\n",
      "Agile at heart, everything is flexible and possible\n",
      "Flat team, nice colleagues, no boss\n",
      "Strong engineering culture, read more of our stories on Medium\n",
      "And some benefits\n",
      "\n",
      "The flexible working environment in terms of time, office\n",
      "Social insurance and comprehensive health care insurance included\n",
      "Support 50% to buy a new MacBook after passing probation\n",
      "13th month-salary\n",
      "Chances for training and development (learning out-door, training course, soft skills)\n",
      "Having allowances for meals, mobile phone, birthday, special days, traveling\n",
      "Company trip, and many team activities (movies, games, lunch)\n",
      "\n",
      "\n",
      "[[ ## resume ## ]]\n",
      ":unselected: 10 District, HCM :selected: duongvuhung142@gmail.com\n",
      "Soft skills:\n",
      "· Communication and Listening\n",
      "· Teamworking\n",
      "· Self- study\n",
      "· Negotiation\n",
      "· Writing reports and proposals\n",
      "Hard skills:\n",
      "· Python: 1.5 year experience\n",
      "· Custom data and model with YOLOv4 and YOLOv5: 1.5 year experience\n",
      "· Frameworks: OpenCV, TensorFlow: 6 months experience\n",
      "· Algorithms: SVM, Linear regression, KNN, Convolutional neural network, Logistic regression ....\n",
      "· SQL, Power BI: 6 months experience\n",
      "· Mos office: Word, Powerpoint, Excel\n",
      "DUONG VU HUNG AI ENGINEER\n",
      "CAREER GOALS\n",
      "· Become official employee, ontributing my knowledge and skills to the growth and prosperity of the company\n",
      "· Become Team Leader or Project Supervisor within the next 3-4 years and Project Manager within the next 6-7 years\n",
      "EDUCATION\n",
      "HO CHI MINH CITY UNIVERSITY OF TECHNOLOGY 8/2018 - PRESENT\n",
      "· Major : Automation and Control Engineering .\n",
      "· Oriantation: Artificial intelligence.\n",
      "· GPA: 7.74/10.\n",
      "\n",
      "PROJECT\n",
      "· Graduation Thesis: Vision based state recognition of 220Kv and 110kv disconnectors switches in power substations (using YOLOv4 and YOLOV5)\n",
      "· Design robot to help detect state recognition of disconnectors switches and fire incidents in power substations using YOLOV5\n",
      "· Mobile price classification using Support Vector Machine (SVM) and K-Nearest Neighbors(KNN)\n",
      "· Flowers classification using Support Vector Machine (SVM)\n",
      "· Identify diseases on shrimp using YOLOV4\n",
      "· Document scanning based on image processing\n",
      "· Classification of bad debts using Logistic regression model\n",
      "\n",
      "ACTIVITIES\n",
      "· Participating in support for Tuoi Tre Newspaper Career Counseling Day 2020, was held at Ho Chi Minh City University of Technology\n",
      "· Participating in blood donation\n",
      "· Supporting to prevent coronavirus at Ho Chi Minh City University of Technology\n",
      "· Member of the Bach khoa Dormitory Badminton Club\n",
      "\n",
      "## FEW-SHOT EXAMPLE 2\n",
      "[[ ## jd ## ]]\n",
      "ML Engineer needed with experience in Python, PyTorch, Computer Vision, TensorFlow, Keras. Could chair beautiful social both few through. Entire card much rate politics their identify. Pass sing goal during be those.\n",
      "\n",
      "RESPONSIBILITY\n",
      "\n",
      "Develop difference technology projects of 7-Eleven Viet Nam\n",
      "Work closely with product managers and business stakeholders, analyze the requirements and feedback to improve the requirement itself\n",
      "Participate in all stages of agile product development life cycle with Scrum\n",
      "REQUIREMENT\n",
      "\n",
      "1-5 years of experience in handling large data sets (multiple TBs), or development of data mart, data warehouse, data extraction and transformation between systems. \n",
      "Have experience in at least one of the following: PostgreSQL, MongoDB or BigQuery.\n",
      "Build scalable and reliable ETL pipelines and processes to assemble data from a large number and variety of data sources.\n",
      "Designing solutions that provide analytics in real-time.\n",
      "Growing our Data Platform so that new data requirements can be done quickly.\n",
      "Ensure the data quality and consistency with monitoring and support, and play an active role in establishing data governance from different sources.\n",
      "Creating more tools and frameworks for processing big data.\n",
      "Design and build dashboard, report to visualize data.\n",
      "Support the development team to design the features that use analytics data.\n",
      "You will love working with 7-Lab  because\n",
      "\n",
      "“We are cool”\n",
      "\n",
      "Optimizing for scale, handling millions records of data\n",
      "Building real-time retails system at scale with Kafka\n",
      "Developing Retail Management System that includes Ecommerce Website, Loyalty Application, Master Data System, Supply Chain System, Warehouse Management System and POS. Refer on https://www.7-eleven.vn/\n",
      "Morden tech stack (Google Cloud Platform, Docker, Kubernetes, Rancher) and tools (Google Chat, Jira) \n",
      "Catching up with new technologies through the process: experiment, trial, adopt \n",
      "In partnership with Grab, Moca, Google for tech & digital integrations\n",
      "Agile at heart, everything is flexible and possible\n",
      "Flat team, nice colleagues, no boss\n",
      "Strong engineering culture, read more of our stories on Medium\n",
      "And some benefits\n",
      "\n",
      "The flexible working environment in terms of time, office\n",
      "Social insurance and comprehensive health care insurance included\n",
      "Support 50% to buy a new MacBook after passing probation\n",
      "13th month-salary\n",
      "Chances for training and development (learning out-door, training course, soft skills)\n",
      "Having allowances for meals, mobile phone, birthday, special days, traveling\n",
      "Company trip, and many team activities (movies, games, lunch)\n",
      "\n",
      "\n",
      "[[ ## resume ## ]]\n",
      ":unselected: 10 District, HCM :selected: duongvuhung142@gmail.com\n",
      "Soft skills:\n",
      "· Communication and Listening\n",
      "· Teamworking\n",
      "· Self- study\n",
      "· Negotiation\n",
      "· Writing reports and proposals\n",
      "Hard skills:\n",
      "· Python: 1.5 year experience\n",
      "· Custom data and model with YOLOv4 and YOLOv5: 1.5 year experience\n",
      "· Frameworks: OpenCV, TensorFlow: 6 months experience\n",
      "· Algorithms: SVM, Linear regression, KNN, Convolutional neural network, Logistic regression ....\n",
      "· SQL, Power BI: 6 months experience\n",
      "· Mos office: Word, Powerpoint, Excel\n",
      "DUONG VU HUNG AI ENGINEER\n",
      "CAREER GOALS\n",
      "· Become official employee, ontributing my knowledge and skills to the growth and prosperity of the company\n",
      "· Become Team Leader or Project Supervisor within the next 3-4 years and Project Manager within the next 6-7 years\n",
      "EDUCATION\n",
      "HO CHI MINH CITY UNIVERSITY OF TECHNOLOGY 8/2018 - PRESENT\n",
      "· Major : Automation and Control Engineering .\n",
      "· Oriantation: Artificial intelligence.\n",
      "· GPA: 7.74/10.\n",
      "\n",
      "PROJECT\n",
      "· Graduation Thesis: Vision based state recognition of 220Kv and 110kv disconnectors switches in power substations (using YOLOv4 and YOLOV5)\n",
      "· Design robot to help detect state recognition of disconnectors switches and fire incidents in power substations using YOLOV5\n",
      "· Mobile price classification using Support Vector Machine (SVM) and K-Nearest Neighbors(KNN)\n",
      "· Flowers classification using Support Vector Machine (SVM)\n",
      "· Identify diseases on shrimp using YOLOV4\n",
      "· Document scanning based on image processing\n",
      "· Classification of bad debts using Logistic regression model\n",
      "\n",
      "ACTIVITIES\n",
      "· Participating in support for Tuoi Tre Newspaper Career Counseling Day 2020, was held at Ho Chi Minh City University of Technology\n",
      "· Participating in blood donation\n",
      "· Supporting to prevent coronavirus at Ho Chi Minh City University of Technology\n",
      "· Member of the Bach khoa Dormitory Badminton Club\n",
      "\n",
      "## FEW-SHOT EXAMPLE 3\n",
      "[[ ## jd ## ]]\n",
      "ML Engineer needed with experience in TensorFlow, Computer Vision, Keras, PyTorch. Approach wish fine near. Agree long behind stuff how positive tree. Quality team general office painting official.\n",
      "\n",
      "RESPONSIBILITY\n",
      "\n",
      "Develop difference technology projects of 7-Eleven Viet Nam\n",
      "Work closely with product managers and business stakeholders, analyze the requirements and feedback to improve the requirement itself\n",
      "Participate in all stages of agile product development life cycle with Scrum\n",
      "REQUIREMENT\n",
      "\n",
      "1-5 years of experience in handling large data sets (multiple TBs), or development of data mart, data warehouse, data extraction and transformation between systems. \n",
      "Have experience in at least one of the following: PostgreSQL, MongoDB or BigQuery.\n",
      "Build scalable and reliable ETL pipelines and processes to assemble data from a large number and variety of data sources.\n",
      "Designing solutions that provide analytics in real-time.\n",
      "Growing our Data Platform so that new data requirements can be done quickly.\n",
      "Ensure the data quality and consistency with monitoring and support, and play an active role in establishing data governance from different sources.\n",
      "Creating more tools and frameworks for processing big data.\n",
      "Design and build dashboard, report to visualize data.\n",
      "Support the development team to design the features that use analytics data.\n",
      "You will love working with 7-Lab  because\n",
      "\n",
      "“We are cool”\n",
      "\n",
      "Optimizing for scale, handling millions records of data\n",
      "Building real-time retails system at scale with Kafka\n",
      "Developing Retail Management System that includes Ecommerce Website, Loyalty Application, Master Data System, Supply Chain System, Warehouse Management System and POS. Refer on https://www.7-eleven.vn/\n",
      "Morden tech stack (Google Cloud Platform, Docker, Kubernetes, Rancher) and tools (Google Chat, Jira) \n",
      "Catching up with new technologies through the process: experiment, trial, adopt \n",
      "In partnership with Grab, Moca, Google for tech & digital integrations\n",
      "Agile at heart, everything is flexible and possible\n",
      "Flat team, nice colleagues, no boss\n",
      "Strong engineering culture, read more of our stories on Medium\n",
      "And some benefits\n",
      "\n",
      "The flexible working environment in terms of time, office\n",
      "Social insurance and comprehensive health care insurance included\n",
      "Support 50% to buy a new MacBook after passing probation\n",
      "13th month-salary\n",
      "Chances for training and development (learning out-door, training course, soft skills)\n",
      "Having allowances for meals, mobile phone, birthday, special days, traveling\n",
      "Company trip, and many team activities (movies, games, lunch)\n",
      "\n",
      "\n",
      "[[ ## resume ## ]]\n",
      ":unselected: 10 District, HCM :selected: duongvuhung142@gmail.com\n",
      "Soft skills:\n",
      "· Communication and Listening\n",
      "· Teamworking\n",
      "· Self- study\n",
      "· Negotiation\n",
      "· Writing reports and proposals\n",
      "Hard skills:\n",
      "· Python: 1.5 year experience\n",
      "· Custom data and model with YOLOv4 and YOLOv5: 1.5 year experience\n",
      "· Frameworks: OpenCV, TensorFlow: 6 months experience\n",
      "· Algorithms: SVM, Linear regression, KNN, Convolutional neural network, Logistic regression ....\n",
      "· SQL, Power BI: 6 months experience\n",
      "· Mos office: Word, Powerpoint, Excel\n",
      "DUONG VU HUNG AI ENGINEER\n",
      "CAREER GOALS\n",
      "· Become official employee, ontributing my knowledge and skills to the growth and prosperity of the company\n",
      "· Become Team Leader or Project Supervisor within the next 3-4 years and Project Manager within the next 6-7 years\n",
      "EDUCATION\n",
      "HO CHI MINH CITY UNIVERSITY OF TECHNOLOGY 8/2018 - PRESENT\n",
      "· Major : Automation and Control Engineering .\n",
      "· Oriantation: Artificial intelligence.\n",
      "· GPA: 7.74/10.\n",
      "\n",
      "PROJECT\n",
      "· Graduation Thesis: Vision based state recognition of 220Kv and 110kv disconnectors switches in power substations (using YOLOv4 and YOLOV5)\n",
      "· Design robot to help detect state recognition of disconnectors switches and fire incidents in power substations using YOLOV5\n",
      "· Mobile price classification using Support Vector Machine (SVM) and K-Nearest Neighbors(KNN)\n",
      "· Flowers classification using Support Vector Machine (SVM)\n",
      "· Identify diseases on shrimp using YOLOV4\n",
      "· Document scanning based on image processing\n",
      "· Classification of bad debts using Logistic regression model\n",
      "\n",
      "ACTIVITIES\n",
      "· Participating in support for Tuoi Tre Newspaper Career Counseling Day 2020, was held at Ho Chi Minh City University of Technology\n",
      "· Participating in blood donation\n",
      "· Supporting to prevent coronavirus at Ho Chi Minh City University of Technology\n",
      "· Member of the Bach khoa Dormitory Badminton Club\n",
      "\n",
      "## FEW-SHOT EXAMPLE 4\n",
      "[[ ## jd ## ]]\n",
      "Customization and development of AI models for retail applications, including but not limited to customer segmentation, product recommendation, and personalized marketing. Utilize Python, PyTorch, TensorFlow, and other relevant tools to develop high-performance machine learning models.\n",
      "\n",
      "RESPONSIBILITY\n",
      "\n",
      "Develop difference technology projects of 7-Eleven Viet Nam\n",
      "Work closely with product managers and business stakeholders, analyze the requirements and feedback to improve the requirement itself\n",
      "Participate in all stages of agile product development life cycle with Scrum\n",
      "REQUIREMENT\n",
      "\n",
      "1-5 years of experience in handling large data sets (multiple TBs), or development of data mart, data warehouse, data extraction and transformation between systems. \n",
      "Have experience in at least one of the following: PostgreSQL, MongoDB or BigQuery.\n",
      "Build scalable and reliable ETL pipelines and processes to assemble data from a large number and variety of data sources.\n",
      "Designing solutions that provide analytics in real-time.\n",
      "Growing our Data Platform so that new data requirements can be done quickly.\n",
      "Ensure the data quality and consistency with monitoring and support, and play an active role in establishing data governance from different sources.\n",
      "Creating more tools and frameworks for processing big data.\n",
      "Design and build dashboard, report to visualize data.\n",
      "Support the development team to design the features that use analytics data.\n",
      "You will love working with 7-Lab  because\n",
      "\n",
      "“We are cool”\n",
      "\n",
      "Optimizing for scale, handling millions records of data\n",
      "Building real-time retails system at scale with Kafka\n",
      "Developing Retail Management System that includes Ecommerce Website, Loyalty Application, Master Data System, Supply Chain System, Warehouse Management System and POS. Refer on https://www.7-eleven.vn/\n",
      "Morden tech stack (Google Cloud Platform, Docker, Kubernetes, Rancher) and tools (Google Chat, Jira) \n",
      "Catching up with new technologies through the process: experiment, trial, adopt \n",
      "In partnership with Grab, Moca, Google for tech & digital integrations\n",
      "Agile at heart, everything is flexible and possible\n",
      "Flat team, nice colleagues, no boss\n",
      "Strong engineering culture, read more of our stories on Medium\n",
      "And some benefits\n",
      "\n",
      "The flexible working environment in terms of time, office\n",
      "Social insurance and comprehensive health care insurance included\n",
      "Support 50% to buy a new MacBook after passing probation\n",
      "13th month-salary\n",
      "Chances for training and development (learning out-door, training course, soft skills)\n",
      "Having allowances for meals, mobile phone, birthday, special days, traveling\n",
      "Company trip, and many team activities (movies, games, lunch)\n",
      "\n",
      "\n",
      "[[ ## resume ## ]]\n",
      ":unselected: 10 District, HCM :selected: duongvuhung142@gmail.com\n",
      "Soft skills:\n",
      "· Communication and Listening\n",
      "· Teamworking\n",
      "· Self- study\n",
      "· Negotiation\n",
      "· Writing reports and proposals\n",
      "Hard skills:\n",
      "· Python: 1.5 year experience\n",
      "· Custom data and model with YOLOv4 and YOLOv5: 1.5 year experience\n",
      "· Frameworks: OpenCV, TensorFlow: 6 months experience\n",
      "· Algorithms: SVM, Linear regression, KNN, Convolutional neural network, Logistic regression ....\n",
      "· SQL, Power BI: 6 months experience\n",
      "· Mos office: Word, Powerpoint, Excel\n",
      "DUONG VU HUNG AI ENGINEER\n",
      "CAREER GOALS\n",
      "· Become official employee, ontributing my knowledge and skills to the growth and prosperity of the company\n",
      "· Become Team Leader or Project Supervisor within the next 3-4 years and Project Manager within the next 6-7 years\n",
      "EDUCATION\n",
      "HO CHI MINH CITY UNIVERSITY OF TECHNOLOGY 8/2018 - PRESENT\n",
      "· Major : Automation and Control Engineering .\n",
      "· Oriantation: Artificial intelligence.\n",
      "· GPA: 7.74/10.\n",
      "\n",
      "PROJECT\n",
      "· Graduation Thesis: Vision based state recognition of 220Kv and 110kv disconnectors switches in power substations (using YOLOv4 and YOLOV5)\n",
      "· Design robot to help detect state recognition of disconnectors switches and fire incidents in power substations using YOLOV5\n",
      "· Mobile price classification using Support Vector Machine (SVM) and K-Nearest Neighbors(KNN)\n",
      "· Flowers classification using Support Vector Machine (SVM)\n",
      "· Identify diseases on shrimp using YOLOV4\n",
      "· Document scanning based on image processing\n",
      "· Classification of bad debts using Logistic regression model\n",
      "\n",
      "ACTIVITIES\n",
      "· Participating in support for Tuoi Tre Newspaper Career Counseling Day 2020, was held at Ho Chi Minh City University of Technology\n",
      "· Participating in blood donation\n",
      "· Supporting to prevent coronavirus at Ho Chi Minh City University of Technology\n",
      "· Member of the Bach khoa Dormitory Badminton Club\n",
      "\n",
      "The final answer is: $\\boxed{7}$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  38%|███▊      | 33/87 [07:47<32:05, 35.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the job description mentions experience in Deep Learning, Machine Learning, NLP, SQL, Pandas, Statistics, which are all relevant skills for a Data Scientist. The resume also highlights experience with Python, Deep Learning, garden, Statistics, SQL, Pandas, stock, which are also relevant to the role. However, it does not mention experience with geospatial data or map systems, which is mentioned in the job description as an important aspect of the company's superapp ecosystem.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  40%|████      | 35/87 [08:00<18:02, 20.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: I can help you predict a matching score between the job description and resume.\n",
      "\n",
      "Based on the provided text, I will analyze the job description and candidate's resume to determine the best match. Here are my predictions:\n",
      "\n",
      "**Job Description:** Software Engineer needed with experience in Git, Docker, Java, REST APIs.\n",
      "**Resume:**\n",
      "Experienced professional skilled in System Design, past, Java, foot. Thank case rather generation inside. Raise new structure race.\n",
      "\n",
      "**Score:** 4\n",
      "**Explanation:** The job description mentions specific technologies and skills required for the position (Git, Docker, Java), while the resume highlights experience with similar technologies (System Design, Java). However, there are no direct matches between the two. Therefore, I predict a score of 4 out of 10.\n",
      "\n",
      "**Completed:** No\n",
      "\n",
      "Note that this prediction is based on my analysis and may not reflect the actual performance or suitability of the candidate for the position.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  43%|████▎     | 37/87 [08:17<12:08, 14.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8. This score indicates that the job description provided in the job posting matches the skills and experience required by the candidate's resume.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "Note: The output fields are filled with the corresponding values based on the analysis of the input fields \"jd\" and \"resume\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  45%|████▍     | 39/87 [08:34<09:09, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8. This indicates that there are some similarities in the job description and resume, but not enough to guarantee a perfect match.\n",
      "\n",
      "The key areas where the two documents show similarities include:\n",
      "\n",
      "* The use of technical terms related to data science and machine learning\n",
      "* The mention of specific tools and technologies such as Hadoop, Spark, and PySpark\n",
      "* The emphasis on data preprocessing, feature engineering, and model training\n",
      "\n",
      "However, there are also some differences that prevent a perfect match. For example:\n",
      "\n",
      "* The job description mentions the need for \"quick access to legal information\" which is not explicitly mentioned in the resume\n",
      "* The resume does not mention any experience with Power BI or Hugging Face models\n",
      "* There is no mention of specific data visualization tools such as Tableau or D3.js\n",
      "\n",
      "Overall, while there are some similarities between the job description and resume, there are also enough differences to prevent a perfect match.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  46%|████▌     | 40/87 [08:48<09:32, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{10}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 10 because the candidate's resume mentions experience in data science, AI engineering, and machine learning, which are relevant to the job description. The candidate also has a strong background in Python, Big Data, Power BI, and libraries such as pandas, matplotlib, and scikit-learn.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "Note: Since there is no information provided about the candidate's experience or skills that match the job requirements, the score of 10 is based on the general relevance of the candidate's resume to the job description.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  47%|████▋     | 41/87 [08:55<08:19, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the candidate's resume mentions experience in Data Science/AI Engineer, which matches the job description. The candidate also has relevant skills such as Python, Big Data, Power Bi, Libraies and frameworks like pandas, matplotlib, numpy, Apache Hadoop, PySpark, Tools like Power Query, Visualize, BeutifulSoup4, re, os, scikit-learn, SQL, C++, Hugging Face, transformers, PyTorch, Python-Flask, LangChain, NLTK. The candidate's experience in Machine Learning and Deep Learning is also relevant to the job description.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "Note: The score of 8 indicates a good match between the job description and the resume, but it does not guarantee that the candidate will get the job. Other factors such as the quality of the resume, the relevance of the skills mentioned in the resume to the job description, and the fit with the company culture may also play a role in the hiring decision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  48%|████▊     | 42/87 [09:06<08:01, 10.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{10}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 10 because the candidate's resume mentions experience in deep learning, machine learning, NLP, SQL, Pandas, Statistics, which are all relevant to a Data Scientist role. The job description also mentions building real-world AI products that touch millions of users, which aligns with the responsibilities of a Data Scientist.\n",
      "\n",
      "[[ ## completed ## ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  49%|████▉     | 43/87 [09:12<06:55,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is based on the similarity in job description, skills, and experience. The candidate's resume highlights their expertise in Data Science/AI Engineer, while the job description emphasizes software development, data analysis, and problem-solving.\n",
      "\n",
      "The key similarities are:\n",
      "\n",
      "* Both candidates have a strong background in programming languages (Python, Java, etc.)\n",
      "* They both have experience with machine learning models (e.g., TensorFlow, PyTorch)\n",
      "* The candidate's resume mentions their experience with Big Data technologies (Apache Hadoop, Spark) and data visualization tools (Power BI)\n",
      "\n",
      "However, there are also some differences:\n",
      "\n",
      "* The job description requires a Full Stack Engineer, while the candidate's resume focuses on Data Science/AI Engineer\n",
      "* The candidate's resume highlights their expertise in computer vision and natural language processing, which is not mentioned in the job description\n",
      "\n",
      "Overall, the matching score is 8 out of 10, indicating that there are some similarities between the JD and Resume, but also some differences that may make it challenging to find a perfect match.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  53%|█████▎    | 46/87 [09:42<06:24,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8, indicating that the job description provided by the candidate matches most of the requirements specified in the resume. The candidate's experience in developing and fine-tuning machine learning models for computer vision and natural language processing aligns with the job responsibilities mentioned.\n",
      "\n",
      "However, there are some discrepancies in the matching score:\n",
      "\n",
      "* The candidate mentions working on data preprocessing, feature engineering, and data augmentation, which is not explicitly stated in the job description.\n",
      "* The candidate also mentions creating API interfaces for model interaction, which is not mentioned in the job description.\n",
      "* Additionally, the candidate's experience in working with cloud-based products and solutions customized to each industry is not explicitly mentioned.\n",
      "\n",
      "Despite these discrepancies, the overall matching score of 8 suggests that the candidate has a good understanding of the key responsibilities and requirements outlined in the job description.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  59%|█████▊    | 51/87 [12:15<20:16, 33.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is based on the following criteria:\n",
      "\n",
      "* Job Description (JD): 4\n",
      "* Resume: 10\n",
      "\n",
      "Explanation:\n",
      "The job description mentions experience in software engineering, data science, and machine learning. The resume highlights expertise in computer vision, Python, MLOps, PyTorch, TensorFlow, and cloud platforms. While there are some similarities between the two, the JD provides more specific examples of skills and experiences that align with the requirements of the job.\n",
      "\n",
      "The score is calculated as follows:\n",
      "\n",
      "* Job Description (JD): 4/10\n",
      "* Resume: 10/10\n",
      "\n",
      "This suggests that the resume has a higher match to the job description due to its emphasis on technical skills, experience, and industry knowledge.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  60%|█████▉    | 52/87 [12:24<15:23, 26.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the job description mentions \"experienced Full Stack Engineer\" which matches the candidate's skills, but it does not mention any specific programming languages or technologies. The resume also lists Python as a skill, which is mentioned in the job description.\n",
      "\n",
      "However, upon closer inspection of the resume, we can see that the candidate has experience with Data Science and Python, which are relevant to the job description. Additionally, the candidate mentions their ability to use SQL and build Dashboards, which could be useful for data analysis and visualization tasks.\n",
      "\n",
      "Therefore, while the score is 8, it's not a perfect match due to the lack of specific language skills mentioned in the job description.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  64%|██████▍   | 56/87 [13:20<09:02, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8.\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "This match is based on the following similarities:\n",
      "\n",
      "* Both job descriptions mention data analysis, reporting, and dashboard creation.\n",
      "* The resumes highlight relevant skills such as SQL knowledge, Python expertise, and experience with data visualization tools like PowerBI.\n",
      "* The job requirements also emphasize analytical thinking, problem-solving, and communication skills.\n",
      "\n",
      "However, there are some differences in the tone and style of the job descriptions. For example, the JD mentions a \"summer discussion culture\" which is not explicitly mentioned in the resume. Additionally, the job description highlights more technical skills like machine learning and deep learning, whereas the resume focuses on data analysis and visualization.\n",
      "\n",
      "Overall, while there are some discrepancies between the two documents, the matching score suggests that the candidate's skills and experience align well with the requirements of the position.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  66%|██████▌   | 57/87 [13:28<07:24, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8.\n",
      "\n",
      "Explanation: The candidate's experience in data analysis, machine learning, and programming skills are relevant to the job description. However, there are some gaps in their experience, particularly in areas such as cloud computing, big data engineering, and cybersecurity. Additionally, they lack specific experience working with Hadoop, Spark, or other related technologies. Overall, while the candidate has a strong foundation in data analysis and programming, they need to demonstrate more expertise in these areas to match the job requirements.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  69%|██████▉   | 60/87 [13:52<04:37, 10.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8.\n",
      "\n",
      "Explanation: The job description mentions experience in deep modeling, machine learning, NLP, SQL, Pandas, Statistics, and problem-solving mindset. The candidate's resume highlights their experience in data analysis, data science, business intelligence, and strong technical foundation. Although the candidate has some relevant skills, they lack direct experience in deep modeling and high-impact problems like those described in the job description. Therefore, a score of 8 is assigned to this example.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  79%|███████▉  | 69/87 [16:01<05:22, 17.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score is based on the similarity between the job description and the candidate's resume. The key phrases that match are:\n",
      "\n",
      "* \"experience in Git, Docker, Java, REST APIs\" (JD)\n",
      "* \"experienced professional skilled in System Design, past, Java, foot\" (Resume)\n",
      "\n",
      "These phrases indicate a strong background in software development, system design, and data analysis, which aligns with the job requirements. The candidate's experience in machine learning and deep learning is also relevant to the job description.\n",
      "\n",
      "However, there are some differences between the two texts that may affect the matching score:\n",
      "\n",
      "* \"hit summer discussion culture measure ever\" (JD) vs. \"conduct analysis of Vietnam complex political, cultural and socio-economic activities\" (Resume)\n",
      "* \"smart decisioning systems\" (JD) vs. \"grew the Embassy's Facebook fanpage to 3,500 followers in one year\" (Resume)\n",
      "\n",
      "These differences may indicate that the candidate has experience with data-driven decision-making or social media management, which is not explicitly mentioned in the job description.\n",
      "\n",
      "Overall, the matching score of 8 suggests a strong alignment between the job requirements and the candidate's skills and experiences.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  84%|████████▍ | 73/87 [16:31<02:15,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the job description mentions experience in developing and deploying practical AI models, which aligns with the candidate's skills as an AI Engineer. The candidate also mentions working on AI research projects and publications, which further supports this match.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "Note: Since there are no specific details provided about the candidate's experience or achievements that would lead to a higher score, the score of 8 is considered a reasonable match based on the information given.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  89%|████████▊ | 77/87 [17:47<03:00, 18.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score of 8 is based on the similarity between the job description and the candidate's resume. The key phrases that match are:\n",
      "\n",
      "* \"Dẫn dắt việc thiết kế, phát triển và triển khai các mô hình rủi ro\" (Leading design, development, and implementation of risk models)\n",
      "* \"Hướng dẫn kỹ thuật cho các chuyên viên phân tích cấp dưới và các nhóm làm việc đa chức năng\" (Providing technical guidance for junior analysts and multi-functional teams)\n",
      "* \"Thúc đẩy việc áp dụng các kỹ thuật phân tích nâng cao, bao gồm AI/ML, để nâng cao khả năng mô hình hóa\" (Fostering the use of advanced techniques in data analysis, including AI/ML to improve modeling capabilities)\n",
      "\n",
      "The candidate's resume highlights their experience in materials science and processing development, which aligns with the job description. However, there are no specific mentions of risk models or AI/ML applications that would increase the score.\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "Explanation: The matching score is based on the similarity between the job description and the candidate's resume. While the candidate has experience in materials science and processing development, their skills and expertise do not directly align with the job requirements. Therefore, the score of 8 is a reasonable estimate based on the available information.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "No completion status provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  90%|████████▉ | 78/87 [17:58<02:23, 15.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the job description mentions experience in TensorFlow, Computer Vision, Keras, PyTorch, MLOps, which are all relevant skills for a Data Scientist role. The candidate's resume also highlights their experience with Python, Deep Learning, NLP, SQL, Pandas, Statistics, and Machine Learning, which aligns with the job requirements. Additionally, the candidate has experience in building and deploying ML models in production, which is mentioned in the job description as one of the key responsibilities. However, there are no specific examples or projects mentioned that demonstrate their expertise in these areas, so the score is lower than 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  91%|█████████ | 79/87 [18:06<01:48, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is 8 because the job description mentions experience in Deep Learning, Machine Learning, NLP, SQL, Pandas, Statistics, which are all relevant skills for a Data Scientist. The candidate's resume also highlights their experience in Python, Deep Learning, garden, Statistics, SQL, Pandas, stock, which matches some of these skills. However, the candidate lacks experience in computer vision and TensorFlow, which is mentioned in the job description as a requirement.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  92%|█████████▏| 80/87 [18:12<01:18, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "{8}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score of 8 is based on the similarity between the job description and resume. The job description mentions specific skills such as \"Software Engineer needed\", \"permissions management\", \"report data snapshots\", and \"lead user experience decision making\". These skills are also mentioned in the candidate's resume.\n",
      "\n",
      "The candidate has a strong background in software development, with experience in developing permissions management on dashboards and reports for all users on PowerBI. They have also implemented report data snapshots to share report views with other users to address #1 requested feature. Additionally, they led user experience decision making for date parsing and Easy Sharing error messaging.\n",
      "\n",
      "The candidate's resume is well-structured and easy to follow, with clear explanations of their skills and experiences. The code snippets provided in the resume are also relevant to the job description.\n",
      "\n",
      "However, there are a few areas where the candidate could improve:\n",
      "\n",
      "* The candidate mentions that they have experience with Amazon checkout and payment services, but does not provide any specific details about how this experience relates to the job description.\n",
      "* The candidate's resume is missing some specific examples of their work, such as a project or a company they worked for. This makes it difficult to determine the level of their expertise in certain areas.\n",
      "\n",
      "Overall, the matching score of 8 suggests that the candidate has a strong background in software development and has relevant experience in the field. However, there are a few areas where the candidate could improve to increase their chances of getting hired.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  93%|█████████▎| 81/87 [18:29<01:18, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is based on the keywords present in both texts. The job description mentions experience in Git, Docker, Java, REST APIs, while the resume highlights skills in System Design, past experiences with Java, Python, MLOps, PyTorch, TensorFlow, Computer Vision, Cloud, interest, MLOps, Keras, hotel, PyTorch.\n",
      "\n",
      "The key differences are:\n",
      "\n",
      "* The job description mentions specific technologies and frameworks (e.g., Git, Docker, Java), while the resume focuses on general skills.\n",
      "* The resume highlights experience with Python, which is not mentioned in the job description.\n",
      "* The resume also mentions a \"hotel\" as part of the job requirements, which is not present in the job description.\n",
      "\n",
      "Based on these differences, it can be inferred that the matching score is lower due to the lack of specific technologies and frameworks mentioned in the job description.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  94%|█████████▍| 82/87 [18:38<00:58, 11.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "{score: 8, explanation: Not supplied for this particular example. The candidate's experience in ML Engineer needed with experience in TensorFlow, Computer Vision, Keras, PyTorch, MLOps is not sufficient to match the job description. The candidate lacks experience in building high-performance web applications and APIs, which are key responsibilities of a Full Stack Engineer.}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The candidate's resume does not provide enough information about their experience in ML Engineer needed with experience in TensorFlow, Computer Vision, Keras, PyTorch, MLOps. They also lack experience in building high-performance web applications and APIs.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "# FINAL QUERY\n",
      "[[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "{score: 4, explanation: Not supplied for this particular example. The candidate's experience in ML Engineer needed with experience in Python, PyTorch, Computer Vision, TensorFlow, Keras is not sufficient to match the job description. The candidate lacks experience in building high-performance web applications and APIs, which are key responsibilities of a Full Stack Engineer.}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The candidate's resume does not provide enough information about their experience in ML Engineer needed with experience in Python, PyTorch, Computer Vision, TensorFlow, Keras. They also lack experience in building high-performance web applications and APIs.\n",
      "\n",
      "[[ ## completed ## ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  97%|█████████▋| 84/87 [19:37<01:06, 22.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: Here is the response with the corresponding output fields:\n",
      "\n",
      "```markdown\n",
      "# SYSTEM INSTRUCTION\n",
      "Your input fields are:\n",
      "1. `jd` (str): The job description text\n",
      "2. `resume` (str): The candidate's resume text\n",
      "Your output fields are:\n",
      "1. `score` (str): The matching score between JD and Resume (0–10)\n",
      "2. `explanation` (str): The explanation of the matching score\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## jd ## ]]\n",
      "{jd}\n",
      "\n",
      "[[ ## resume ## ]]\n",
      "{resume}\n",
      "\n",
      "[[ ## score ## ]]\n",
      "{score}\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "{explanation}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "```\n",
      "\n",
      "Let me know if you'd like me to fill in any specific details or examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph:  99%|█████████▉| 86/87 [19:54<00:15, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing LLM output: Could not find score or explanation tags in the output.\n",
      "Response: [[ ## score ## ]]\n",
      "8\n",
      "\n",
      "[[ ## explanation ## ]]\n",
      "The matching score between JD and Resume is based on the similarity in job description, skills, and experience. The candidate's resume highlights their relevant experience as a Full Stack Engineer, while the job description emphasizes the need for an experienced engineer with expertise in web development, APIs, and software testing.\n",
      "\n",
      "The key similarities are:\n",
      "\n",
      "* Experience in building modern web applications\n",
      "* Proficiency in Java/Kotlin/Go/Rust/Python programming languages\n",
      "* Strong understanding of computer science fundamentals, data structures, and algorithms\n",
      "\n",
      "However, there are also some differences that might affect the matching score:\n",
      "\n",
      "* The job description mentions a \"summer discussion culture\" which is not explicitly mentioned in the candidate's resume.\n",
      "* The candidate's experience with cloud-based technologies (e.g., AWS/GCP) is not highlighted in the job description.\n",
      "\n",
      "Overall, while the candidate's resume provides relevant information about their skills and experience, the job description might require some additional context or clarification to fully match.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LangGraph: 100%|██████████| 87/87 [20:02<00:00, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluation Complete ---\n",
      "\n",
      "--- LangGraph Evaluation Results ---\n",
      "📊 Mean Absolute Error (MAE): 4.3793\n",
      "---\n",
      "🎯 Accuracy@1 (error <= 1.0): 26.44%\n",
      "🎯 Accuracy@2 (error <= 2.0): 34.48%\n",
      "🎯 Accuracy@3 (error <= 3.0): 40.23%\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "collected_folder = \"/Users/nhannguyen/ngtuthanhan@gmail.com - Google Drive/My Drive/HCMUS/LLM/Data_Collector_30_8\"\n",
    "matching_json = os.path.join(collected_folder, \"Matching_Result.json\")\n",
    "\n",
    "with open(matching_json, \"r\") as f:\n",
    "    matching_data = json.load(f)\n",
    "\n",
    "pred_scores = []\n",
    "gold_scores = []\n",
    "\n",
    "for example in tqdm(\n",
    "    matching_data, desc=\"Evaluating LangGraph\", total=len(matching_data)\n",
    "):\n",
    "    jd_path = example[\"JD\"]\n",
    "    resume_path = example[\"CV\"]\n",
    "    gold_score = example[\"Score\"]\n",
    "    with open(os.path.join(collected_folder, \"JD\", jd_path) + \".txt\", \"r\") as f:\n",
    "        jd = f.read()\n",
    "    with open(os.path.join(collected_folder, \"CV\", resume_path) + \".txt\", \"r\") as f:\n",
    "        resume = f.read()\n",
    "    inputs = {\"jd\": jd, \"resume\": resume}\n",
    "    try:\n",
    "        result = app.invoke(inputs)\n",
    "        pred_score = result[\"prediction\"].score\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during graph execution: {e}\")\n",
    "        pred_score = 0.0  # Assign a penalty score\n",
    "\n",
    "    gold_scores.append(gold_score)\n",
    "    pred_scores.append(pred_score)\n",
    "\n",
    "    # To avoid rate limiting\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "print(\"--- Evaluation Complete ---\")\n",
    "\n",
    "# --- Calculate Metrics ---\n",
    "\n",
    "# 1. Mean Absolute Error (MAE)\n",
    "final_mae = mean_absolute_error(gold_scores, pred_scores)\n",
    "\n",
    "# 2. Accuracy@threshold\n",
    "acc_at_1 = accuracy_at_threshold(gold_scores, pred_scores, threshold=1)\n",
    "acc_at_2 = accuracy_at_threshold(gold_scores, pred_scores, threshold=2)\n",
    "acc_at_3 = accuracy_at_threshold(gold_scores, pred_scores, threshold=3)\n",
    "\n",
    "\n",
    "# --- Print Results ---\n",
    "\n",
    "print(\"\\n--- LangGraph Evaluation Results ---\")\n",
    "print(f\"📊 Mean Absolute Error (MAE): {final_mae:.4f}\")\n",
    "print(\"---\")\n",
    "print(f\"🎯 Accuracy@1 (error <= 1.0): {acc_at_1:.2%}\")\n",
    "print(f\"🎯 Accuracy@2 (error <= 2.0): {acc_at_2:.2%}\")\n",
    "print(f\"🎯 Accuracy@3 (error <= 3.0): {acc_at_3:.2%}\")\n",
    "print(\"--------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a9532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
